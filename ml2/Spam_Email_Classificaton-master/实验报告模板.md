# 垃圾邮件分类实验报告

## 一、实验目的

本实验旨在使用逻辑回归算法实现垃圾邮件分类任务，通过理论分析和实验验证，深入理解逻辑回归模型的原理和应用，并评估模型在实际文本分类问题上的性能。

## 二、理论分析

### 2.1 逻辑回归模型原理

逻辑回归是一种用于二分类问题的统计学习方法。它通过sigmoid函数将线性模型的输出映射到[0,1]区间，表示样本属于正类的概率。

**决策函数**：
$$h_\theta(x) = g(\theta^T x) = \frac{1}{1+e^{-\theta^T x}}$$
其中，$g(z) = \frac{1}{1+e^{-z}}$ 为sigmoid函数，$\theta$ 为模型参数，$x$ 为特征向量。

当 $\theta^T x \geq 0$ 时，$h_\theta(x) \geq 0.5$，模型将样本预测为正类（垃圾邮件）；当 $\theta^T x < 0$ 时，$h_\theta(x) < 0.5$，模型将样本预测为负类（非垃圾邮件）。

### 2.2 似然函数与参数估计

为了求解逻辑回归模型的参数$\theta$，我们采用最大似然估计法。

**似然函数**：
$$L(\theta) = \prod_{i=1}^{m} h_\theta(x^{(i)})^{y^{(i)}} (1-h_\theta(x^{(i)}))^{1-y^{(i)}}$$
其中，$m$ 为样本数量，$y^{(i)}$ 为第 $i$ 个样本的真实标签（1表示垃圾邮件，0表示非垃圾邮件）。

为了方便计算，我们取对数似然函数：
$$\ell(\theta) = \log L(\theta) = \sum_{i=1}^{m} [y^{(i)} \log h_\theta(x^{(i)}) + (1-y^{(i)}) \log (1-h_\theta(x^{(i)}))]$$

最大化对数似然函数等价于最小化负对数似然函数（即损失函数）。我们可以使用梯度上升法（或梯度下降法）来求解参数$\theta$。

### 2.3 参数更新公式推导

对对数似然函数求关于$\theta_j$的偏导数：

$$\frac{\partial \ell(\theta)}{\partial \theta_j} = \sum_{i=1}^{m} \left[ y^{(i)} \frac{1}{h_\theta(x^{(i)})} \frac{\partial h_\theta(x^{(i)})}{\partial \theta_j} + (1-y^{(i)}) \frac{-1}{1-h_\theta(x^{(i)})} \frac{\partial h_\theta(x^{(i)})}{\partial \theta_j} \right]$$

由于sigmoid函数的导数满足 $g'(z) = g(z)(1-g(z))$，因此：

$$\frac{\partial h_\theta(x^{(i)})}{\partial \theta_j} = h_\theta(x^{(i)})(1-h_\theta(x^{(i)})) x_j^{(i)}$$

代入上式并化简，得到：

$$\frac{\partial \ell(\theta)}{\partial \theta_j} = \sum_{i=1}^{m} (y^{(i)} - h_\theta(x^{(i)})) x_j^{(i)}$$

因此，参数更新公式为：

$$\theta_j := \theta_j + \alpha \sum_{i=1}^{m} (y^{(i)} - h_\theta(x^{(i)})) x_j^{(i)}$$

其中，$\alpha$ 为学习率，控制参数更新的步长。

## 三、数据准备

### 3.1 数据集介绍

本实验使用的数据集为`train.csv`，位于`data`文件夹中。该数据集包含4458条邮件数据，其中非垃圾邮件（ham）3866条，垃圾邮件（spam）592条，属于不平衡数据集。

数据集格式如下：
- ID：邮件唯一标识符
- Label：邮件标签（ham表示非垃圾邮件，spam表示垃圾邮件）
- Email：邮件内容

### 3.2 数据预处理

为了提高模型性能，我们对邮件文本进行了以下预处理操作：

1. **转换为小写**：将所有字符转换为小写，消除大小写差异
2. **移除URL**：使用正则表达式移除邮件中的网址链接
3. **移除标点符号**：移除所有标点符号，减少噪声
4. **移除停用词**：使用NLTK库中的英文停用词表，移除常见但信息量低的单词
5. **词干提取**：使用PorterStemmer将单词还原为词干形式，减少词汇量

预处理代码实现如下：

```python
def text_processing(text):
    # 转为小写
    text = text.lower()
    # 移除URL
    text = re.compile(r'https?://\S+|www\.\S+').sub(r'', text)
    # 移除标点符号
    PUNCT_TO_REMOVE = string.punctuation
    text = text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))
    # 移除停用词
    STOPWORDS = set(stopwords.words("english"))
    text = " ".join([word for word in str(text).split() if word not in STOPWORDS])
    # 词干提取
    stemmer = PorterStemmer()
    text = " ".join([stemmer.stem(word) for word in text.split()])
    return text
```

### 3.3 数据集划分

将预处理后的数据集按照8:2的比例划分为训练集和测试集：
- 训练集：3566条邮件（用于模型训练）
- 测试集：892条邮件（用于模型评估）

## 四、模型实现

### 4.1 特征提取

本实验采用词袋模型结合TF-IDF方法进行特征提取：

1. **词袋模型（Bag of Words）**：使用CountVectorizer将邮件文本转换为词频矩阵
2. **TF-IDF转换**：使用TfidfTransformer将词频矩阵转换为TF-IDF特征矩阵

TF-IDF（Term Frequency-Inverse Document Frequency）考虑了词在文档中的重要性，能够有效提升模型性能。

特征提取代码实现如下：

```python
# 词袋模型
vectorizer = CountVectorizer()
X_train_counts = vectorizer.fit_transform(X_train)
X_test_counts = vectorizer.transform(X_test)

# TF-IDF转换
transformer = TfidfTransformer()
X_train_tfidf = transformer.fit_transform(X_train_counts)
X_test_tfidf = transformer.transform(X_test_counts)
```

### 4.2 模型训练

使用scikit-learn库中的LogisticRegression类进行模型训练，具体参数设置如下：
- max_iter=150：最大迭代次数为150
- penalty='l2'：使用L2正则化，防止过拟合
- solver='lbfgs'：使用lbfgs优化算法
- random_state=0：设置随机种子，保证结果可复现

模型训练代码实现如下：

```python
# 逻辑回归模型训练
lr_model = LogisticRegression(max_iter=150, penalty='l2', solver='lbfgs', random_state=0)
lr_model.fit(X_train_tfidf, y_train)
```

## 五、性能评估

### 5.1 评估指标

本实验使用以下指标评估模型性能：

1. **准确率（Accuracy）**：分类正确的样本数占总样本数的比例
2. **ROC曲线（Receiver Operating Characteristic Curve）**：反映分类器在不同阈值下的真阳性率（TPR）和假阳性率（FPR）之间的权衡
3. **AUC值（Area Under ROC Curve）**：ROC曲线下的面积，用于综合评估分类器性能
4. **混淆矩阵（Confusion Matrix）**：直观展示分类器在不同类别上的分类结果

### 5.2 绘制ROC曲线

ROC曲线的绘制过程如下：

1. 获取模型对测试集样本的预测概率
2. 计算不同阈值下的真阳性率（TPR）和假阳性率（FPR）
3. 以FPR为横轴，TPR为纵轴，绘制ROC曲线
4. 计算ROC曲线下的面积（AUC值）

绘制ROC曲线的代码实现如下：

```python
def plot_roc_curve(y_true, y_score, model_name):
    # 计算ROC曲线点
    fpr, tpr, _ = roc_curve(y_true, y_score)
    # 计算AUC值
    roc_auc = auc(fpr, tpr)
    
    # 绘制ROC曲线
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, 
             label='ROC曲线 (面积 = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('假阳性率 (FPR)')
    plt.ylabel('真阳性率 (TPR)')
    plt.title(f'{model_name} 的ROC曲线')
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.savefig(f'roc_curve_{model_name}.png')  # 保存ROC曲线图像
```

### 5.3 实验结果

实验结果如下：

1. **准确率**：0.9596（95.96%）
2. **AUC值**：0.9894

ROC曲线和混淆矩阵图像已保存为`roc_curve_逻辑回归.png`和`confusion_matrix_逻辑回归.png`文件。

## 六、结论

### 6.1 实验总结

本实验使用逻辑回归算法成功实现了垃圾邮件分类任务。通过对邮件文本的预处理和特征提取，结合逻辑回归模型的训练和评估，我们得到了以下结论：

1. **模型性能**：逻辑回归模型在垃圾邮件分类任务上表现优异，准确率达到95.96%，AUC值接近0.99，表明模型具有很高的分类性能和稳定性。

2. **特征工程重要性**：通过TF-IDF特征提取方法，能够有效捕获邮件文本的特征，提升分类性能。数据预处理步骤（如移除停用词、词干提取等）也对模型性能有积极影响。

3. **算法适用性**：逻辑回归作为一种简单高效的分类算法，在处理文本分类问题上具有较好的实用性，可以作为垃圾邮件过滤系统的基础模型。

### 6.2 改进方向

未来可以从以下几个方面进一步改进模型性能：

1. **集成更多特征**：可以尝试添加更多特征，如词嵌入（Word Embedding）、n-gram特征等，进一步提升模型性能。

2. **尝试深度学习模型**：可以考虑使用循环神经网络（RNN）、长短期记忆网络（LSTM）等深度学习模型，利用其更强的特征学习能力。

3. **处理不平衡数据**：由于数据集存在类别不平衡问题（垃圾邮件占比较少），可以尝试使用过采样、欠采样或类别权重调整等方法，提高模型对少数类的识别能力。

4. **超参数调优**：可以通过网格搜索、随机搜索等方法对模型的超参数进行调优，进一步提升模型性能。

## 七、参考文献

[1] 李航. 统计学习方法[M]. 北京: 清华大学出版社, 2019.
[2] 周志华. 机器学习[M]. 北京: 清华大学出版社, 2016.
[3] https://github.com/ljx02/Spam_Email_Classificaton

## 八、附录

### 8.1 完整代码

见`logistic_regression_spam_classification.py`文件。

### 8.2 生成的图像

1. `roc_curve_逻辑回归.png`：逻辑回归模型的ROC曲线
2. `confusion_matrix_逻辑回归.png`：逻辑回归模型的混淆矩阵